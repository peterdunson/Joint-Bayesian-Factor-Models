---
title: "log1p_moms"
output:
  html_document:
    code_folding: hide
---


```{r fig.width=14, fig.height=14, out.width='100%'}
setwd("/Users/peterdunson/Desktop/Joint-Bayesian-Factor-Models/ciprian_sim/nhanes")
dat <- readRDS("nhanes_phthalates_adults.rds")

dat <- log1p(dat)

# ---- Plot Correlation Matrix (Raw Data) ----
library(pheatmap)

Y_raw <- scale(dat, center = TRUE, scale = TRUE)  # If you want raw (unscaled), use: Y_raw <- as.matrix(dat)
cor_raw <- cor(Y_raw)
pheatmap(
  cor_raw,
  cluster_rows = FALSE, cluster_cols = FALSE,
  color = colorRampPalette(c("white", "pink", "red"))(100),
  main = "Correlation Matrix (All Variables)",
  show_rownames = TRUE, show_colnames = TRUE,
  labels_row = colnames(Y_raw), labels_col = colnames(Y_raw),
  fontsize_row = 9, fontsize_col = 9
)

# ---- Pairwise Scatterplot Matrix (Raw Data) ----
pairs(Y_raw, labels = colnames(Y_raw), main = "Scatterplot Matrix (All Variables)")


```


```{r fig.width=14, fig.height=6, out.width='100%'}
# MoM-Trio scores
set.seed(26031980)

# 1) Prepare data
Y <- scale(dat, center = TRUE, scale = TRUE)
P <- ncol(Y)
n <- nrow(Y)

# 2) MoM-Trio estimator
C <- cov(Y)
lambda2_est <- numeric(P)
for (p in 1:P) {
  vals <- c()
  idx  <- setdiff(1:P, p)
  for (i in seq_along(idx)) {
    q <- idx[i]
    for (r in idx[-seq_len(i)]) {
      if (abs(C[q, r]) > 0.02) {
        vals <- c(vals, C[p, q] * C[p, r] / C[q, r])
      }
    }
  }
  lambda2_est[p] <- mean(vals, na.rm = TRUE)
}
lambda_trio <- sign(lambda2_est) * sqrt(abs(lambda2_est))
lambda_trio <- lambda_trio / sqrt(sum(lambda_trio^2)) # L2 normalize

# MoM-Trio scores
b_trio <- as.numeric(Y %*% lambda_trio) / sum(lambda_trio^2)

# 1. Subject-level dataframe
df_subjects <- data.frame(
  subject     = 1:nrow(Y),
  lambda1_bi  = round(lambda_trio[1] * b_trio, 6),
  bi          = round(b_trio, 6)
)
cat("\nFirst 10 subject scores (lambda1_bi, bi):\n")
print(head(df_subjects, 10), row.names = FALSE)

# 2. Variable-level dataframe
df_loadings <- data.frame(
  variable = colnames(Y),
  loading  = round(lambda_trio, 6)
)
cat("\nMoM-Trio estimated K=1 loadings (L2 normalized):\n")
print(df_loadings, row.names = FALSE)

# 3. One-row dataframe with all lambdas
df_all_lambdas <- as.data.frame(t(lambda_trio))
colnames(df_all_lambdas) <- paste0("lambda", seq_len(P))
cat("\nAll loadings in one row (lambda1, ..., lambdaP):\n")
print(round(df_all_lambdas, 6), row.names = FALSE)

# Plots (unchanged)
par(mfrow = c(1, 2))
barplot(lambda_trio, 
        main = "MoM-Trio estimated loadings",
        names.arg = colnames(Y), las = 2, col = "skyblue")
hist(b_trio, breaks = 30, 
     main = "MoM-Trio estimated factor scores",
     xlab = "b_trio", col = "orange")
par(mfrow = c(1, 1))

```



```{r}
# Paths to fits (already loaded as shown)
fit_dir <- "/Users/peterdunson/Desktop/Joint-Bayesian-Factor-Models/ciprian_sim/nhanes"
fit_MGSP <- readRDS(file.path(fit_dir, "fit_Joint_NHANES1718_k1_log.rds"))
fit_HS   <- readRDS(file.path(fit_dir, "fit_HS_NHANES1718_k1_log.rds"))
fit_SSL  <- readRDS(file.path(fit_dir, "fit_SSL_NHANES1718_k1_log.rds"))

# --- Overwrite fit$Lambda_hat with normalized loadings (only ONCE here) ---
fit_MGSP$Lambda_hat <- as.numeric(fit_MGSP$Lambda_hat)
fit_MGSP$Lambda_hat <- fit_MGSP$Lambda_hat / sqrt(sum(fit_MGSP$Lambda_hat^2))

fit_HS$Lambda_hat <- as.numeric(fit_HS$Lambda_hat)
fit_HS$Lambda_hat <- fit_HS$Lambda_hat / sqrt(sum(fit_HS$Lambda_hat^2))

fit_SSL$Lambda_hat <- as.numeric(fit_SSL$Lambda_hat)
fit_SSL$Lambda_hat <- fit_SSL$Lambda_hat / sqrt(sum(fit_SSL$Lambda_hat^2))

# Your Y matrix:
Y <- scale(dat, center = TRUE, scale = TRUE)
n <- nrow(Y)
P <- ncol(Y)

# Function to create all 3 dataframes for a fit (no normalization here)
make_fit_dfs <- function(Lambda_hat, Y) {
  lambda <- as.numeric(Lambda_hat)                   # ensure vector (already normalized)
  
  # Factor scores
  b <- as.numeric(Y %*% lambda)

  # 1. Subject-level dataframe
  df_subjects <- data.frame(
    subject    = 1:nrow(Y),
    lambda1_bi = round(lambda[1] * b, 6),
    bi         = round(b, 6)
  )

  # 2. Variable-level dataframe
  df_loadings <- data.frame(
    variable = colnames(Y),
    loading  = round(lambda, 6)
  )

  # 3. One-row dataframe with all lambdas
  df_all_lambdas <- as.data.frame(t(lambda))
  colnames(df_all_lambdas) <- paste0("lambda", seq_len(P))

  list(
    subjects    = df_subjects,
    loadings    = df_loadings,
    all_lambdas = df_all_lambdas
  )
}

# Example usage (works exactly as before):
mgsp_dfs <- make_fit_dfs(fit_MGSP$Lambda_hat, Y)
hs_dfs   <- make_fit_dfs(fit_HS$Lambda_hat, Y)
ssl_dfs  <- make_fit_dfs(fit_SSL$Lambda_hat, Y)

```


```{r}
# MGSP
mgsp_dfs <- make_fit_dfs(fit_MGSP$Lambda_hat, Y)
cat("\nMGSP: First 10 subjects\n")
print(head(mgsp_dfs$subjects, 10), row.names = FALSE)
cat("\nMGSP: Loadings\n")
print(mgsp_dfs$loadings, row.names = FALSE)
cat("\nMGSP: All lambdas (one row)\n")
print(mgsp_dfs$all_lambdas, row.names = FALSE)
```



```{r}
# HS
hs_dfs <- make_fit_dfs(fit_HS$Lambda_hat, Y)
cat("\nHS: First 10 subjects\n")
print(head(hs_dfs$subjects, 10), row.names = FALSE)
cat("\nHS: Loadings\n")
print(hs_dfs$loadings, row.names = FALSE)
cat("\nHS: All lambdas (one row)\n")
print(hs_dfs$all_lambdas, row.names = FALSE)
```



```{r}

# SSL
ssl_dfs <- make_fit_dfs(fit_SSL$Lambda_hat, Y)
cat("\nSSL: First 10 subjects\n")
print(head(ssl_dfs$subjects, 10), row.names = FALSE)
cat("\nSSL: Loadings\n")
print(ssl_dfs$loadings, row.names = FALSE)
cat("\nSSL: All lambdas (one row)\n")
print(ssl_dfs$all_lambdas, row.names = FALSE)
```






```{r fig.width=14, fig.height=6, out.width='100%'}
# Plot squared loadings (lambda^2)
plot_loadings_squared <- function(loadings, varnames = NULL, main = "Squared Factor Loadings", ylim = NULL) {
  lambda2 <- loadings^2
  if (is.null(varnames)) varnames <- paste0("V", seq_along(loadings))
  if (is.null(ylim)) ylim <- c(0, max(lambda2))
  barplot(lambda2, names.arg = varnames, las = 2,
          col = "orchid", main = main, ylim = ylim, cex.names = 0.7)
  abline(h = 0, col = "gray60")
}

# Example usage:

# For MoM-Trio:
plot_loadings_squared(lambda_trio, varnames = colnames(Y), main = "MoM-Trio Squared Loadings")

# For MGSP:
plot_loadings_squared(as.numeric(fit_MGSP$Lambda_hat), varnames = colnames(Y), main = "MGSP Squared Loadings")

# For Horseshoe:
plot_loadings_squared(as.numeric(fit_HS$Lambda_hat), varnames = colnames(Y), main = "Horseshoe Squared Loadings")

# For Spike-and-Slab:
plot_loadings_squared(as.numeric(fit_SSL$Lambda_hat), varnames = colnames(Y), main = "Spike-and-Slab Squared Loadings")

```



```{r fig.width=14, fig.height=6, out.width='100%'}
# Collect all loadings squared as rows in a matrix
lambda2_matrix <- rbind(
  MoM_Trio      = lambda_trio^2,
  MGSP          = as.numeric(fit_MGSP$Lambda_hat)^2,
  Horseshoe     = as.numeric(fit_HS$Lambda_hat)^2,
  Spike_and_Slab= as.numeric(fit_SSL$Lambda_hat)^2
)

colnames(lambda2_matrix) <- colnames(Y)

# Install and load pheatmap if needed
if (!requireNamespace("pheatmap", quietly = TRUE)) install.packages("pheatmap")
library(pheatmap)

# Plot heatmap: each row is a method, columns are variables, color is lambda^2
pheatmap(lambda2_matrix,
         cluster_rows = FALSE,
         cluster_cols = FALSE,
         color = colorRampPalette(c("white", "pink", "red"))(100),
         main = "Squared Factor Loadings (λ²) by Method",
         fontsize_row = 12, fontsize_col = 9, angle_col = 45)

```




```{r fig.width=14, fig.height=6, out.width='100%'}
# Function to compute all vdiffs for a vector of loadings and a covariance matrix
compute_vdiff_all <- function(lambda, C, threshold = 0.02) {
  P <- length(lambda)
  lambda2 <- lambda^2
  vdiff_all <- unlist(lapply(1:P, function(p) {
    idx <- setdiff(1:P, p)
    v <- c()
    for (i in seq_along(idx)) for (r in idx[-seq_len(i)]) {
      if (abs(C[idx[i], r]) > threshold)
        v <- c(v, lambda2[p] * C[idx[i], r] - C[p, idx[i]] * C[p, r])
    }
    v
  }))
  return(vdiff_all)
}

# Compute all vdiff vectors
vdiff_trio <- compute_vdiff_all(lambda_trio, cov(Y))
vdiff_mgsp <- compute_vdiff_all(as.numeric(fit_MGSP$Lambda_hat), cov(Y))
vdiff_hs   <- compute_vdiff_all(as.numeric(fit_HS$Lambda_hat),   cov(Y))
vdiff_ssl  <- compute_vdiff_all(as.numeric(fit_SSL$Lambda_hat),  cov(Y))

# Compute symmetric x-axis limits
get_xlim <- function(x) {
  m <- max(abs(range(x, na.rm = TRUE)))
  c(-m, m)
}

par(mfrow = c(2, 2))

hist(vdiff_trio, breaks = 50,
     main = "MoM-Trio",
     xlab = expression(lambda[p]^2 ~ "C[q,r] - C[p,q]C[p,r]"),
     col = rgb(0.2, 0.6, 0.2, 0.5),
     xlim = get_xlim(vdiff_trio))
abline(v = 0, col = "blue", lwd = 2)

hist(vdiff_mgsp, breaks = 50,
     main = "MGSP",
     xlab = expression(lambda[p]^2 ~ "C[q,r] - C[p,q]C[p,r]"),
     col = rgb(0.5, 0.2, 0.7, 0.5),
     xlim = get_xlim(vdiff_mgsp))
abline(v = 0, col = "blue", lwd = 2)

hist(vdiff_hs, breaks = 50,
     main = "Horseshoe",
     xlab = expression(lambda[p]^2 ~ "C[q,r] - C[p,q]C[p,r]"),
     col = rgb(0.1, 0.6, 0.8, 0.5),
     xlim = get_xlim(vdiff_hs))
abline(v = 0, col = "blue", lwd = 2)

hist(vdiff_ssl, breaks = 50,
     main = "Spike-and-Slab",
     xlab = expression(lambda[p]^2 ~ "C[q,r] - C[p,q]C[p,r]"),
     col = rgb(0.9, 0.7, 0.2, 0.5),
     xlim = get_xlim(vdiff_ssl))
abline(v = 0, col = "blue", lwd = 2)

par(mfrow = c(1, 1))


```


```{r}
plot_resid_vs_b <- function(b, lambda, X, method_name) {
   P <- ncol(X)
   par(mfrow = c(3, 4), mar = c(4,4,2,1))
   for (p in 1:P) {
      eps <- X[, p] - lambda[p] * b
      corr_val <- cor(b, eps)
      plot(b, eps,
           xlab = "b_i", ylab = expression(epsilon[ ip ]),
           main = paste0(method_name, ": ", colnames(X)[p], "\ncor=", round(corr_val,2)),
           pch  = 20, cex = 0.6)
      abline(h=0, col="gray")
   }
   par(mfrow = c(1,1))
}

# MoM-Trio
plot_resid_vs_b(b_trio, lambda_trio, Y, "MoM-Trio")

# MGSP
lambda_mgsp <- as.numeric(fit_MGSP$Lambda_hat)
b_mgsp      <- as.numeric(Y %*% lambda_mgsp)
plot_resid_vs_b(b_mgsp, lambda_mgsp, Y, "MGSP")

# Horseshoe
lambda_hs <- as.numeric(fit_HS$Lambda_hat)
b_hs      <- as.numeric(Y %*% lambda_hs)
plot_resid_vs_b(b_hs, lambda_hs, Y, "Horseshoe")

# Spike-and-Slab
lambda_ssl <- as.numeric(fit_SSL$Lambda_hat)
b_ssl      <- as.numeric(Y %*% lambda_ssl)
plot_resid_vs_b(b_ssl, lambda_ssl, Y, "Spike-and-Slab")

```



```{r fig.width=14, fig.height=6, out.width='100%'}
library(pheatmap)
library(gridExtra)

plot_cor_before_after_side_by_side <- function(Y, lambda, b, method_name) {
  cor_before <- cor(Y)
  fitted     <- outer(b, lambda)
  cor_after  <- cor(Y - fitted)
  
  # Color scale
  breaks <- seq(-1, 1, length.out = 101)
  colors <- colorRampPalette(c("blue", "white", "red"))(100)
  
  # Show variable names
  var_names <- colnames(Y)
  
  ph1 <- pheatmap(
    cor_before, cluster_rows = FALSE, cluster_cols = FALSE,
    color = colors, breaks = breaks,
    main = "Before",
    show_rownames = TRUE, show_colnames = TRUE,
    labels_row = var_names, labels_col = var_names,
    fontsize_row = 9, fontsize_col = 9,
    silent = TRUE
  )
  ph2 <- pheatmap(
    cor_after, cluster_rows = FALSE, cluster_cols = FALSE,
    color = colors, breaks = breaks,
    main = "After",
    show_rownames = TRUE, show_colnames = TRUE,
    labels_row = var_names, labels_col = var_names,
    fontsize_row = 9, fontsize_col = 9,
    silent = TRUE
  )
  
  grid.arrange(
    ph1$gtable, ph2$gtable,
    ncol = 2,
    top = method_name
  )
}

# Example for each method (run one at a time, or in a loop)
plot_cor_before_after_side_by_side(Y, lambda_trio, b_trio, "MoM-Trio")
plot_cor_before_after_side_by_side(Y, lambda_mgsp, b_mgsp, "MGSP")
plot_cor_before_after_side_by_side(Y, lambda_hs,   b_hs,   "Horseshoe")
plot_cor_before_after_side_by_side(Y, lambda_ssl,  b_ssl,  "Spike-and-Slab")

```



```{r}
# ---- Find and Plot Most Negative Residual Correlations: Spike-and-Slab ----

# 1. Get residuals for SSL
fitted_ssl <- outer(b_ssl, lambda_ssl)
Y_resid_ssl <- Y - fitted_ssl

# 2. Compute residual correlation matrix
cor_resid_ssl <- cor(Y_resid_ssl)

# 3. Get upper triangle indices (excluding diagonal)
upper_idx <- which(upper.tri(cor_resid_ssl), arr.ind = TRUE)

# 4. Extract the actual correlations
resid_cors <- cor_resid_ssl[upper.tri(cor_resid_ssl)]

# 5. Sort to get the 4 most negative correlations
sorted_neg <- order(resid_cors)  # ascending order (most negative first)
N <- 4
top_neg_pairs <- upper_idx[sorted_neg[1:N], , drop = FALSE]

# 6. Plot side-by-side scatterplots for each top negative pair
par(mfrow = c(N, 2), mar = c(4, 4, 3, 1))
for (i in 1:N) {
  p1 <- top_neg_pairs[i, 1]
  p2 <- top_neg_pairs[i, 2]
  
  # Before (original)
  plot(Y[, p1], Y[, p2],
       xlab = colnames(Y)[p1], ylab = colnames(Y)[p2],
       main = sprintf("Before: %s vs %s", colnames(Y)[p1], colnames(Y)[p2]),
       pch = 20, col = rgb(0.2, 0.2, 0.7, 0.5))
  
  # After (residual)
  plot(Y_resid_ssl[, p1], Y_resid_ssl[, p2],
       xlab = colnames(Y)[p1], ylab = colnames(Y)[p2],
       main = sprintf("After: %s vs %s\nResidual cor = %.3f",
                      colnames(Y)[p1], colnames(Y)[p2],
                      cor_resid_ssl[p1, p2]),
       pch = 20, col = rgb(0.7, 0.2, 0.2, 0.5))
}
par(mfrow = c(1, 1))

```


```{r fig.width=14, fig.height=14, out.width='100%'}
# ---- MoM-Trio ----
Y_resid_trio <- Y - outer(b_trio, lambda_trio)
par(mfrow = c(1,2))
pairs(Y, labels = colnames(Y), main = "MoM-Trio: Before K=1 Removal", pch=20, col=rgb(0.2,0.2,0.7,0.4), cex=0.7)
pairs(Y_resid_trio, labels = colnames(Y), main = "MoM-Trio: After K=1 Removal", pch=20, col=rgb(0.9,0.1,0.1,0.4), cex=0.7)
par(mfrow = c(1,1))

# ---- MGSP ----
Y_resid_mgsp <- Y - outer(b_mgsp, lambda_mgsp)
par(mfrow = c(1,2))
pairs(Y, labels = colnames(Y), main = "MGSP: Before K=1 Removal", pch=20, col=rgb(0.2,0.2,0.7,0.4), cex=0.7)
pairs(Y_resid_mgsp, labels = colnames(Y), main = "MGSP: After K=1 Removal", pch=20, col=rgb(0.9,0.1,0.1,0.4), cex=0.7)
par(mfrow = c(1,1))

# ---- Horseshoe ----
Y_resid_hs <- Y - outer(b_hs, lambda_hs)
par(mfrow = c(1,2))
pairs(Y, labels = colnames(Y), main = "Horseshoe: Before K=1 Removal", pch=20, col=rgb(0.2,0.2,0.7,0.4), cex=0.7)
pairs(Y_resid_hs, labels = colnames(Y), main = "Horseshoe: After K=1 Removal", pch=20, col=rgb(0.9,0.1,0.1,0.4), cex=0.7)
par(mfrow = c(1,1))

# ---- Spike-and-Slab ----
Y_resid_ssl <- Y - outer(b_ssl, lambda_ssl)
par(mfrow = c(1,2))
pairs(Y, labels = colnames(Y), main = "Spike-and-Slab: Before K=1 Removal", pch=20, col=rgb(0.2,0.2,0.7,0.4), cex=0.7)
pairs(Y_resid_ssl, labels = colnames(Y), main = "Spike-and-Slab: After K=1 Removal", pch=20, col=rgb(0.9,0.1,0.1,0.4), cex=0.7)
par(mfrow = c(1,1))

```



```{r}
#permutation_null

fisher_z <- function(r) 0.5 * log((1 + r) / (1 - r))

# Helper: DSC calculation
dsc <- function(corrs, mu2, sd2, sk2, ku2) {
   mu1 <- mean(corrs)
   sd1 <- sd(corrs)
   sk1 <- if (sd1 < 1e-12) 0 else mean((corrs - mu1)^3) / sd1^3
   ku1 <- if (sd1 < 1e-12) 0 else mean((corrs - mu1)^4) / sd1^4
   sk_diff <- abs(sk1)^(1/3) - abs(sk2)^(1/3)
   ku_diff <- abs(ku1)^(1/4) - abs(ku2)^(1/4)
   sqrt((mu1 - mu2)^2 + (sd1 - sd2)^2 + sk_diff^2 + ku_diff^2)
}

# 1. DSC for observed data, with permutation null
dsc_with_permutation_null_obs <- function(Y, B = 1000) {
   n <- nrow(Y)
   # Observed
   R_obs <- cor(Y)
   z_obs <- fisher_z(R_obs[lower.tri(R_obs)])
   # Permutation null
   dsc_null <- numeric(B)
   mu2s <- sd2s <- sk2s <- ku2s <- numeric(B)
   for (b in 1:B) {
      Y_perm <- apply(Y, 2, sample)
      R_perm <- cor(Y_perm)
      z_perm <- fisher_z(R_perm[lower.tri(R_perm)])
      mu2s[b] <- mean(z_perm)
      sd2s[b] <- sd(z_perm)
      sk2s[b] <- if (sd2s[b] < 1e-12) 0 else mean((z_perm - mu2s[b])^3) / sd2s[b]^3
      ku2s[b] <- if (sd2s[b] < 1e-12) 0 else mean((z_perm - mu2s[b])^4) / sd2s[b]^4
      dsc_null[b] <- dsc(z_obs, mu2s[b], sd2s[b], sk2s[b], ku2s[b])
   }
   # Center null on mean (can also report full null dist)
   dsc_obs <- dsc(z_obs, mean(mu2s), mean(sd2s), mean(sk2s), mean(ku2s))
   list(
      dsc_obs = dsc_obs,
      dsc_null = dsc_null,
      dsc_obs_stats = c(mean = mean(z_obs), sd = sd(z_obs),
                        skew = if (sd(z_obs) < 1e-12) 0 else mean((z_obs - mean(z_obs))^3) / sd(z_obs)^3,
                        kurt = if (sd(z_obs) < 1e-12) 0 else mean((z_obs - mean(z_obs))^4) / sd(z_obs)^4)
   )
}

# 2. DSC for residuals (after removing K factors), with permutation null
dsc_with_permutation_null_resid <- function(Y, Lambda_hat, B = 1000) {
   n <- nrow(Y)
   # Project out factors
   eta_hat <- Y %*% Lambda_hat %*% solve(t(Lambda_hat) %*% Lambda_hat)
   Y_hat <- eta_hat %*% t(Lambda_hat)
   resid <- Y - Y_hat
   R_resid <- cor(resid)
   z_resid <- fisher_z(R_resid[lower.tri(R_resid)])
   # Permutation null
   dsc_null <- numeric(B)
   mu2s <- sd2s <- sk2s <- ku2s <- numeric(B)
   for (b in 1:B) {
      resid_perm <- apply(resid, 2, sample)
      R_perm <- cor(resid_perm)
      z_perm <- fisher_z(R_perm[lower.tri(R_perm)])
      mu2s[b] <- mean(z_perm)
      sd2s[b] <- sd(z_perm)
      sk2s[b] <- if (sd2s[b] < 1e-12) 0 else mean((z_perm - mu2s[b])^3) / sd2s[b]^3
      ku2s[b] <- if (sd2s[b] < 1e-12) 0 else mean((z_perm - mu2s[b])^4) / sd2s[b]^4
      dsc_null[b] <- dsc(z_resid, mu2s[b], sd2s[b], sk2s[b], ku2s[b])
   }
   dsc_resid <- dsc(z_resid, mean(mu2s), mean(sd2s), mean(sk2s), mean(ku2s))
   list(
      dsc_resid = dsc_resid,
      dsc_null = dsc_null,
      dsc_resid_stats = c(mean = mean(z_resid), sd = sd(z_resid),
                          skew = if (sd(z_resid) < 1e-12) 0 else mean((z_resid - mean(z_resid))^3) / sd(z_resid)^3,
                          kurt = if (sd(z_resid) < 1e-12) 0 else mean((z_resid - mean(z_resid))^4) / sd(z_resid)^4)
   )
}
```



```{r fig.width=14, fig.height=14, out.width='100%'}
# Utility: upper triangle extraction
get_upper <- function(mat) mat[upper.tri(mat)]

# One permutation null (change seed for different draws)
set.seed(12)
Y_perm <- apply(Y, 2, sample)
cor_null <- cor(Y_perm)
offdiag_null <- get_upper(cor_null)

# Overlay function: histogram + null density (classic style)
plot_hist_with_null <- function(x, null, main, col="dodgerblue", after=FALSE) {
  # Plot main histogram
  hist(x, breaks=30, col=col, border="white", xlim=c(-1,1),
       main=main, xlab="Correlation", freq=FALSE)
  # Add permutation null as dashed line
  lines(density(null), lwd=2, lty=2, col="black")
  legend("topright", legend=c(ifelse(after, "After", "Before"), "Permutation Null"),
         col=c(col, "black"), lwd=2, lty=c(1,2), bty="n", cex=0.9)
}

# ---- MoM-Trio ----
cor_before_trio <- cor(Y)
cor_after_trio  <- cor(Y_resid_trio)
offdiag_before_trio <- get_upper(cor_before_trio)
offdiag_after_trio  <- get_upper(cor_after_trio)

# ---- MGSP ----
cor_before_mgsp <- cor(Y)
cor_after_mgsp  <- cor(Y_resid_mgsp)
offdiag_before_mgsp <- get_upper(cor_before_mgsp)
offdiag_after_mgsp  <- get_upper(cor_after_mgsp)

# ---- Horseshoe ----
cor_before_hs <- cor(Y)
cor_after_hs  <- cor(Y_resid_hs)
offdiag_before_hs <- get_upper(cor_before_hs)
offdiag_after_hs  <- get_upper(cor_after_hs)

# ---- Spike-and-Slab ----
cor_before_ssl <- cor(Y)
cor_after_ssl  <- cor(Y_resid_ssl)
offdiag_before_ssl <- get_upper(cor_before_ssl)
offdiag_after_ssl  <- get_upper(cor_after_ssl)

# ---- Plot: Before (blue) ----
par(mfrow = c(1,1))
plot_hist_with_null(offdiag_before_trio, offdiag_null, "Before", col="dodgerblue")
par(mfrow = c(1,1))

# ---- Plot: After (red) ----
par(mfrow = c(2,2), mar = c(4,4,3,1))
plot_hist_with_null(offdiag_after_trio, offdiag_null, "MoM-Trio: After", col="firebrick", after=TRUE)
plot_hist_with_null(offdiag_after_mgsp, offdiag_null, "MGSP: After", col="firebrick", after=TRUE)
plot_hist_with_null(offdiag_after_hs, offdiag_null, "Horseshoe: After", col="firebrick", after=TRUE)
plot_hist_with_null(offdiag_after_ssl, offdiag_null, "Spike-and-Slab: After", col="firebrick", after=TRUE)
par(mfrow = c(1,1))


B <- 500

# Original data
dsc_before <- dsc_with_permutation_null_obs(Y, B = B)
dsc_orig   <- dsc_before$dsc_obs

# Each method (assuming you have Lambda_hat for each)
dsc_trio    <- dsc_with_permutation_null_resid(Y, matrix(lambda_trio, ncol = 1), B = B)
dsc_mgsp    <- dsc_with_permutation_null_resid(Y, matrix(lambda_mgsp, ncol = 1), B = B)
dsc_hs      <- dsc_with_permutation_null_resid(Y, matrix(lambda_hs, ncol = 1), B = B)
dsc_ssl     <- dsc_with_permutation_null_resid(Y, matrix(lambda_ssl, ncol = 1), B = B)

# Combine into a table
dsc_table <- data.frame(
  Method = c("Original Data", "MoM-Trio Residual", "MGSP Residual", "Horseshoe Residual", "Spike-and-Slab Residual"),
  DSC = round(c(dsc_orig, dsc_trio$dsc_resid, dsc_mgsp$dsc_resid, dsc_hs$dsc_resid, dsc_ssl$dsc_resid), 3)
)

print(dsc_table)


```



```{r fig.width=14, fig.height=14, out.width='100%'}
# ---- Visualize observed vs predicted (per subject) for each method ----
setwd("/Users/peterdunson/Desktop/Joint-Bayesian-Factor-Models/ciprian_sim/nhanes")
dat <- readRDS("nhanes_phthalates_adults.rds")
#dat <- log1p(dat)
Y <- scale(dat, center = TRUE, scale = TRUE)

plot_subject_fits <- function(Y, lambda, b, method_name, n_show=5) {
  set.seed(42)
  subject_ids <- sample(1:nrow(Y), n_show)
  varnames <- colnames(Y)
  par(mfrow=c(1, n_show), mar=c(4,4,2,1))
  for (i in subject_ids) {
    obs  <- as.numeric(Y[i, ])
    pred <- as.numeric(b[i] * lambda)
    plot(obs, type="b", pch=16, col="black", ylim=range(c(obs, pred)), 
         xaxt='n', ylab="Z-score", xlab="Variable", main=paste0("Subject ", i))
    points(pred, type="b", pch=1, col="red")
    axis(1, at=1:length(varnames), labels=varnames, las=2, cex.axis=0.7)
    legend("topright", legend=c("Observed", "Predicted"), col=c("black","red"),
           lty=1, pch=c(16,1), bty="n", cex=0.9)
  }
  title(method_name, outer=TRUE, line=-2)
  par(mfrow=c(1,1))
}

# MoM-Trio
plot_subject_fits(Y, lambda_trio, b_trio, "MoM-Trio")

# MGSP
plot_subject_fits(Y, lambda_mgsp, b_mgsp, "MGSP")

# Horseshoe
plot_subject_fits(Y, lambda_hs, b_hs, "Horseshoe")

# Spike-and-Slab
plot_subject_fits(Y, lambda_ssl, b_ssl, "Spike-and-Slab")

```

```{r}
plot_subject_fit_for_id <- function(Y, lambda, b, method_name, subject_id) {
  varnames <- colnames(Y)
  obs  <- as.numeric(Y[subject_id, ])
  pred <- as.numeric(b[subject_id] * lambda)
  par(mfrow=c(1,1), mar=c(4,4,2,1))
  plot(obs, type="b", pch=16, col="black", ylim=range(c(obs, pred)),
       xaxt='n', ylab="Z-score", xlab="Variable", 
       main=paste0(method_name, ": Subject ", subject_id))
  points(pred, type="b", pch=1, col="red")
  axis(1, at=1:length(varnames), labels=varnames, las=2, cex.axis=0.7)
  legend("topright", legend=c("Observed", "Predicted"), col=c("black","red"),
         lty=1, pch=c(16,1), bty="n", cex=0.9)
}

# For MoM-Trio
plot_subject_fit_for_id(Y, lambda_trio, b_trio, "MoM-Trio", 1118)

# For MGSP
plot_subject_fit_for_id(Y, lambda_mgsp, b_mgsp, "MGSP", 1118)

# For Horseshoe
plot_subject_fit_for_id(Y, lambda_hs, b_hs, "Horseshoe", 1118)

# For Spike-and-Slab
plot_subject_fit_for_id(Y, lambda_ssl, b_ssl, "Spike-and-Slab", 1118)

```



```{r}
# ---- MoM-Trio Bootstrap: CIs for loadings and scores (NHANES) ----

setwd("/Users/peterdunson/Desktop/Joint-Bayesian-Factor-Models/ciprian_sim/nhanes")
dat <- readRDS("nhanes_phthalates_adults.rds")
dat <- log1p(dat)
Y <- scale(dat, center = TRUE, scale = TRUE)

set.seed(888)
nboot <- 2000
n     <- nrow(Y)
P     <- ncol(Y)
lambda_boot <- matrix(NA, nboot, P)
b_boot      <- matrix(NA, nboot, n)


for (b in 1:nboot) {
  idx <- sample(1:n, replace = TRUE)
  Yb  <- Y[idx, ]

  # MoM-Trio estimator
  Cb <- cov(Yb)
  lambda2b <- numeric(P)
  for (p in 1:P) {
    vals <- c()
    others <- setdiff(1:P, p)
    for (i in seq_along(others)) {
      q <- others[i]
      for (r in others[-seq_len(i)]) {
        if (abs(Cb[q, r]) > 0.02) {
          vals <- c(vals, Cb[p, q] * Cb[p, r] / Cb[q, r])
        }
      }
    }
    lambda2b[p] <- mean(vals, na.rm = TRUE)
  }
  lambda_b <- sign(lambda2b) * sqrt(abs(lambda2b))
  # Normalize
  lambda_b <- lambda_b / sqrt(sum(lambda_b^2))
  b_b      <- as.numeric(Y %*% lambda_b) / sum(lambda_b^2)

  lambda_boot[b, ] <- lambda_b
  b_boot[b, ]      <- b_b
}

# Loadings CIs (95%)
lambda_ci <- t(apply(lambda_boot, 2, quantile, probs = c(0.025, 0.5, 0.975), na.rm=TRUE))
colnames(lambda_ci) <- c("lower", "median", "upper")
rownames(lambda_ci) <- colnames(Y)
cat("\n=== 95% CIs for MoM-Trio Loadings (NHANES) ===\n")
print(lambda_ci)

# Subject score CIs (first 5 subjects)
b_ci <- t(apply(b_boot, 2, quantile, probs = c(0.025, 0.5, 0.975), na.rm=TRUE))
colnames(b_ci) <- c("lower", "median", "upper")
cat("\n=== 95% CIs for MoM-Trio b_i (first 5 subjects, NHANES) ===\n")
print(b_ci[1:5, ])



# Optional: Plot the CIs for all loadings
par(mfrow = c(1, 1))
matplot(1:P, lambda_ci, type = "l", lty = c(2,1,2), col = c("gray30","red","gray30"),
        main = "MoM-Trio Loadings (NHANES, Bootstrap 95% CIs)", xlab = "Variable", ylab = "Loading",
        xaxt = "n")
axis(1, at = 1:P, labels = colnames(Y), las = 2, cex.axis=0.7)
legend("topright", legend = c("Lower", "Median", "Upper"), lty = c(2,1,2), col = c("gray30","red","gray30"), bty="n")

# Optional: Show one subject's score CIs
subject_id <- 1
cat(sprintf("\nSubject %d: 95%% CI for b = (%.3f, %.3f)\n", subject_id, b_ci[subject_id,1], b_ci[subject_id,3]))

# --- Plot MoM-Trio Lambda Squared (λ²) Bootstrap CIs ---

# Compute λ² for all bootstrap samples
lambda2_boot <- lambda_boot^2

# 95% CIs for λ²
lambda2_ci <- t(apply(lambda2_boot, 2, quantile, probs = c(0.025, 0.5, 0.975), na.rm = TRUE))
colnames(lambda2_ci) <- c("lower", "median", "upper")
rownames(lambda2_ci) <- colnames(Y)

cat("\n=== 95% CIs for MoM-Trio Lambda Squared (λ², NHANES) ===\n")
print(round(lambda2_ci, 5))

# Plot
par(mfrow = c(1, 1))
matplot(1:P, lambda2_ci, type = "l", lty = c(2,1,2), col = c("gray50", "red", "gray50"),
        main = "MoM-Trio Lambda Squared (Bootstrap 95% CIs)", xlab = "Variable", ylab = expression(lambda^2),
        xaxt = "n")
axis(1, at = 1:P, labels = colnames(Y), las = 2, cex.axis = 0.7)
legend("topright", legend = c("Lower", "Median", "Upper"),
       lty = c(2,1,2), col = c("gray50", "red", "gray50"), bty = "n")

```




```{r}
# ---- Compare lambda1_bi (subject-level first factor scores) between methods ----

# Create a data frame with all methods' lambda1_bi
compare_lambda1_bi <- data.frame(
  MoM_Trio      = lambda_trio[1]    * b_trio,
  MGSP          = lambda_mgsp[1]    * b_mgsp,
  Horseshoe     = lambda_hs[1]      * b_hs,
  Spike_and_Slab= lambda_ssl[1]     * b_ssl
)

# Example: Compare MoM-Trio vs MGSP
plot(compare_lambda1_bi$MoM_Trio, compare_lambda1_bi$MGSP,
     xlab = "MoM-Trio: lambda1_bi", ylab = "MGSP: lambda1_bi",
     main = "MoM-Trio vs MGSP: lambda1_bi",
     pch = 20, col = rgb(0.2,0.2,0.7,0.5))
abline(0,1,col="red",lwd=2)
grid()

# Add correlation for reference
cor_val <- cor(compare_lambda1_bi$MoM_Trio, compare_lambda1_bi$MGSP)
legend("topleft", legend = sprintf("Corr = %.3f", cor_val), bty = "n")

# --- Repeat for other pairs as needed ---

# MoM-Trio vs Horseshoe
plot(compare_lambda1_bi$MoM_Trio, compare_lambda1_bi$Horseshoe,
     xlab = "MoM-Trio: lambda1_bi", ylab = "Horseshoe: lambda1_bi",
     main = "MoM-Trio vs Horseshoe: lambda1_bi",
     pch = 20, col = rgb(0.2,0.7,0.2,0.5))
abline(0,1,col="red",lwd=2)
grid()
cor_val <- cor(compare_lambda1_bi$MoM_Trio, compare_lambda1_bi$Horseshoe)
legend("topleft", legend = sprintf("Corr = %.3f", cor_val), bty = "n")

# MoM-Trio vs Spike-and-Slab
plot(compare_lambda1_bi$MoM_Trio, compare_lambda1_bi$Spike_and_Slab,
     xlab = "MoM-Trio: lambda1_bi", ylab = "Spike-and-Slab: lambda1_bi",
     main = "MoM-Trio vs Spike-and-Slab: lambda1_bi",
     pch = 20, col = rgb(0.7,0.2,0.2,0.5))
abline(0,1,col="red",lwd=2)
grid()
cor_val <- cor(compare_lambda1_bi$MoM_Trio, compare_lambda1_bi$Spike_and_Slab)
legend("topleft", legend = sprintf("Corr = %.3f", cor_val), bty = "n")

# You can also look at all pairwise scatterplots at once:
pairs(compare_lambda1_bi, main = "Pairwise lambda1_bi: All Methods", pch=20, cex=0.7)

```


```{r}
# --- 95% Credible Intervals for Lambda Squared (λ²) and Subject Scores: ALL METHODS ---

methods <- list(
  MGSP = fit_MGSP,
  Horseshoe = fit_HS,
  Spike_and_Slab = fit_SSL
)

for (meth in names(methods)) {
  fit <- methods[[meth]]
  # Lambda: [iterations × P × 1]
  lambda_samples <- drop(fit$posterior$Lambda)
  colnames(lambda_samples) <- colnames(Y)
  
  # Compute lambda squared samples
  lambda2_samples <- lambda_samples^2
  
  # Credible intervals for lambda squared
  lambda2_ci <- t(apply(lambda2_samples, 2, quantile, probs = c(0.025, 0.5, 0.975), na.rm=TRUE))
  colnames(lambda2_ci) <- c("lower", "median", "upper")
  rownames(lambda2_ci) <- colnames(Y)
  
  cat("\n=== 95% Credible Intervals for", meth, "Lambda Squared (λ²) ===\n")
  print(round(lambda2_ci, 4))
  
  # Plot
  P <- ncol(lambda2_samples)
  par(mfrow = c(1, 1), mar = c(8, 4, 3, 1))
  matplot(1:P, lambda2_ci, type = "l", lty = c(2,1,2), col = c("gray50","red","gray50"),
          main = paste(meth, "Lambda Squared (λ²) (95% Credible Intervals)"), xlab = "", ylab = expression(lambda^2),
          xaxt = "n")
  axis(1, at = 1:P, labels = colnames(Y), las = 2, cex.axis=0.7)
  legend("topright", legend = c("Lower", "Median", "Upper"), lty = c(2,1,2), col = c("gray50","red","gray50"), bty="n")
  
  # Subject scores (eta): [iterations × n × 1]
  eta_samples <- drop(fit$posterior$eta)
  n <- ncol(eta_samples)
  eta_ci <- t(apply(eta_samples, 2, quantile, probs = c(0.025, 0.5, 0.975), na.rm=TRUE))
  colnames(eta_ci) <- c("lower", "median", "upper")
  rownames(eta_ci) <- paste0("subject", 1:n)
  
  cat("\n=== 95% Credible Intervals for", meth, "b_i (first 5 subjects) ===\n")
  print(round(eta_ci[1:5, ], 4))
}

# Restore graphics defaults if needed
par(mfrow=c(1,1), mar=c(5,4,4,2)+0.1)

```



